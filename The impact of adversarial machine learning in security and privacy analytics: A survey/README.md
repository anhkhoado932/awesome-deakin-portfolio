## Key Results

- Identified taxonomy of adversarial attacks based on attack phase (training/testing) and attacker knowledge (whitebox, graybox, blackbox).
- Reviewed recent advancements in poisoning attacks (e.g., backdoor triggers, label flipping) and evasion attacks (e.g., Carlini & Wagner, Square Attack).
- Discussed defense strategies including adversarial training, data sanitization, gradient masking, and differential privacy.
- Summarized five major adversarial robustness/privacy analytics tools: Adversarial Robustness Toolbox, RobustML, Cleverhans, ARX Anonymization Tool, and Diffprivlib.
- Illustrated that real-world systems implement multi-layered defenses but still face challenges from sophisticated adversarial methods.

## Technology Used

![](https://img.shields.io/badge/Python-3776ab?style=flat&logo=python&logoColor=white) ![](https://img.shields.io/badge/ART-F7931E?style=flat&logo=python&logoColor=white) ![](https://img.shields.io/badge/RobustML-000000?style=flat&logo=python&logoColor=white) ![](https://img.shields.io/badge/Cleverhans-0052cc?style=flat&logo=python&logoColor=white) ![](https://img.shields.io/badge/ARX-1E90FF?style=flat&logo=java&logoColor=white) ![](https://img.shields.io/badge/Diffprivlib-0066CC?style=flat&logo=python&logoColor=white) ![](https://img.shields.io/badge/scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white) ![](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white) ![](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)
